{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Shayakhmetov Rim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Data - Tic Tac Toe Endgame\n",
    "https://archive.ics.uci.edu/ml/datasets/Tic-Tac-Toe+Endgame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "import sklearn.cross_validation\n",
    "import sklearn.ensemble\n",
    "import sklearn.grid_search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Creating csv file for convenience purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = ['top-left-square', 'top-middle-square', 'top-right-square', 'middle-left-square', 'middle-middle-square', 'middle-right-square', 'bottom-left-square', 'bottom-middle-square', 'bottom-right-square', 'Class']\n",
    "data = pd.read_csv('tic-tac-toe.data', header=None)\n",
    "data.columns = columns\n",
    "data.Class = data.Class.map(lambda x: 1 if x == 'positive' else 0)\n",
    "data.to_csv('tic-tac-toe.csv', index=False)\n",
    "data = pd.get_dummies(data)\n",
    "X = data.ix[:, 1:].values\n",
    "y = data.ix[:, 0].values\n",
    "for train_index, test_index in sklearn.cross_validation.StratifiedShuffleSplit(y, n_iter=1, test_size=0.3):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###the data is divided to train and test. the train is used for hyperparameter tuning (cross-validation) and the test is used for a quality measure to avoid overfitting on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyClassifier():\n",
    "    def __init__(self, min_supp=0.9, min_similarity=0.7):\n",
    "        self.min_supp = min_supp\n",
    "        self.min_similarity = min_similarity\n",
    "        \n",
    "    def __predict_one(self, x):\n",
    "        pos_intersection = (self.pos*x)\n",
    "        pos_conf = (pos_intersection == x).sum(axis=1)/x.shape[0]\n",
    "        neg_intersection = (self.neg*x)\n",
    "        neg_conf = (neg_intersection == x).sum(axis=1)/x.shape[0]\n",
    "\n",
    "        pos_intersection = pos_intersection[pos_conf >= min(self.min_similarity, pos_conf.max())]\n",
    "        neg_intersection = neg_intersection[neg_conf >= min(self.min_similarity, neg_conf.max())]\n",
    "\n",
    "        pos_dash = (pos_intersection.dot(pos_intersection.T) ==\n",
    "                    pos_intersection.sum(axis=1).reshape(pos_intersection.shape[0], 1))\n",
    "        pos_dash = pos_dash.sum(axis=1)/self.pos.shape[0]\n",
    "        pos_dash = pos_dash[pos_dash >= min(self.min_supp, pos_dash.max())]\n",
    "\n",
    "        neg_dash = (neg_intersection.dot(neg_intersection.T) ==\n",
    "                    neg_intersection.sum(axis=1).reshape(neg_intersection.shape[0], 1))\n",
    "        neg_dash = neg_dash.sum(axis=1)/self.neg.shape[0]\n",
    "        neg_dash = neg_dash[neg_dash >= min(self.min_supp, neg_dash.max())]\n",
    "        \n",
    "        pos_coeff = pos_dash.mean()\n",
    "        neg_coeff = neg_dash.mean()\n",
    "        \n",
    "        c = 1/(pos_coeff + neg_coeff)\n",
    "        return [c*neg_coeff, c*pos_coeff]\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.pos, self.neg = X[y == 1], X[y == 0]\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return [np.argmax(l) for l in self.predict_proba(X)]\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return np.array([self.__predict_one(x) for x in X])\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {'min_supp': self.min_supp, 'min_similarity': self.min_similarity}\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###The classification algorithm is:<ul><li>for a test example find it's intersections with the positive and negative context</li><li>filter intersections that have low hamming similarity with the test example</li><li>find support of each intersection according to the context</li><li>filter by the minimum support value</li><li>find weights for the positive and negative context as the mean of remaining support values</li><li>normalize weights to get probabilities of a positive and negative class</li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Some hyperparameters tuning    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'min_similarity': 0.68421052631578938, 'min_supp': 0.0}, 0.90746268656716422)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = sklearn.cross_validation.StratifiedKFold(y_train, n_folds=10, shuffle=True)\n",
    "clf = MyClassifier()\n",
    "gs = sklearn.grid_search.RandomizedSearchCV(clf, {'min_supp': np.linspace(0, 1, 20), \n",
    "                                                  'min_similarity': np.linspace(0.7, 1, 20)},\n",
    "                                            scoring='accuracy', n_jobs=-1, n_iter=100, cv=skf, error_score=0)\n",
    "gs.fit(X_train, y_train)\n",
    "gs.best_params_, gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TP(y_true, y_pred):\n",
    "    confusion_matrix = sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
    "    return confusion_matrix[0,0]\n",
    "\n",
    "def TN(y_true, y_pred):\n",
    "    confusion_matrix = sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
    "    return confusion_matrix[1,1]\n",
    "\n",
    "def FP(y_true, y_pred):\n",
    "    confusion_matrix = sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
    "    return confusion_matrix[1,0]\n",
    "\n",
    "def FN(y_true, y_pred):\n",
    "    confusion_matrix = sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
    "    return confusion_matrix[0,1]\n",
    "\n",
    "def TPR(y_true, y_pred):\n",
    "    return TP(y_true, y_pred)/(TP(y_true, y_pred) + FN(y_true, y_pred))\n",
    "\n",
    "def TNR(y_true, y_pred):\n",
    "    return TN(y_true, y_pred)/(TN(y_true, y_pred) + FP(y_true, y_pred))\n",
    "\n",
    "def NPV(y_true, y_pred):\n",
    "    return TN(y_true, y_pred)/(TN(y_true, y_pred) + FN(y_true, y_pred))\n",
    "\n",
    "def FPR(y_true, y_pred):\n",
    "    return FP(y_true, y_pred)/(FP(y_true, y_pred) + TN(y_true, y_pred))\n",
    "\n",
    "def FDR(y_true, y_pred):\n",
    "    return FP(y_true, y_pred)/(FP(y_true, y_pred) + TP(y_true, y_pred))\n",
    "\n",
    "def TNR(y_true, y_pred):\n",
    "    return TN(y_true, y_pred)/(TN(y_true, y_pred) + FP(y_true, y_pred))\n",
    "\n",
    "metrics = [TP, TN, FP, FN, TPR, TNR, NPV, FPR, FDR, TNR,\n",
    "           sklearn.metrics.accuracy_score, sklearn.metrics.precision_score,\n",
    "           sklearn.metrics.recall_score, sklearn.metrics.roc_auc_score, sklearn.metrics.f1_score]\n",
    "metrics_names = [func.__name__ for func in metrics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Predicting the test based on the train with optimal hyperparameters for MyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP = 94\n",
      "TN = 171\n",
      "FP = 17\n",
      "FN = 6\n",
      "TPR = 0.94\n",
      "TNR = 0.909574468085\n",
      "NPV = 0.966101694915\n",
      "FPR = 0.0904255319149\n",
      "FDR = 0.153153153153\n",
      "TNR = 0.909574468085\n",
      "accuracy_score = 0.920138888889\n",
      "precision_score = 0.966101694915\n",
      "recall_score = 0.909574468085\n",
      "roc_auc_score = 0.924787234043\n",
      "f1_score = 0.93698630137\n"
     ]
    }
   ],
   "source": [
    "clf = gs.best_estimator_\n",
    "# clf = MyClassifier(min_similarity=0.9, min_supp=0.4)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "for metric_name, metric in zip(metrics_names, metrics):\n",
    "    score = metric(y_test, y_pred)\n",
    "    print(metric_name, '=', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Just checking the accuracy on the whole data set using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.94882471966\n"
     ]
    }
   ],
   "source": [
    "skf = sklearn.cross_validation.StratifiedKFold(y, n_folds=10, shuffle=True)\n",
    "scores = sklearn.cross_validation.cross_val_score(clf, X, y, scoring='accuracy', n_jobs=-1, cv=skf)\n",
    "print('Accuracy', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Random Forest benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 10, 'n_estimators': 450}, 0.98656716417910451)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = sklearn.cross_validation.StratifiedKFold(y_train, n_folds=10, shuffle=True)\n",
    "clf = sklearn.ensemble.RandomForestClassifier()\n",
    "gs = sklearn.grid_search.RandomizedSearchCV(clf, {'n_estimators': np.arange(10, 500, 10), \n",
    "                                                  'max_depth': np.arange(3, 15)},\n",
    "                                            scoring='accuracy', n_jobs=-1, n_iter=100, cv=skf, error_score=0)\n",
    "gs.fit(X_train, y_train)\n",
    "gs.best_params_, gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP = 95\n",
      "TN = 188\n",
      "FP = 0\n",
      "FN = 5\n",
      "TPR = 0.95\n",
      "TNR = 1.0\n",
      "NPV = 0.974093264249\n",
      "FPR = 0.0\n",
      "FDR = 0.0\n",
      "TNR = 1.0\n",
      "accuracy_score = 0.982638888889\n",
      "precision_score = 0.974093264249\n",
      "recall_score = 1.0\n",
      "roc_auc_score = 0.975\n",
      "f1_score = 0.98687664042\n"
     ]
    }
   ],
   "source": [
    "clf = gs.best_estimator_\n",
    "# clf = sklearn.ensemble.RandomForestClassifier(n_estimators=500, max_depth=10)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "for metric_name, metric in zip(metrics_names, metrics):\n",
    "    score = metric(y_test, y_pred)\n",
    "    print(metric_name, '=', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.991655475674\n"
     ]
    }
   ],
   "source": [
    "skf = sklearn.cross_validation.StratifiedKFold(y, n_folds=10, shuffle=True)\n",
    "scores = sklearn.cross_validation.cross_val_score(clf, X, y, scoring='accuracy', n_jobs=-1, cv=skf)\n",
    "print('Accuracy', scores.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
